version: '3.8'

services:
  anythingllm:
    image: mintplexlabs/anythingllm:latest
    container_name: anythingllm
    ports:
      - "3001:3001"
    volumes:
      - ./anythingllm-storage:/app/server/storage
      - ./custom-skills:/app/server/storage/plugins/agent-skills:ro
    environment:
      - STORAGE_DIR=/app/server/storage
      - SERVER_PORT=3001
      # Uncomment and configure these if needed:
      # - LLM_PROVIDER=openai
      # - OPENAI_API_KEY=${MISTRAL_API_KEY}
      # - OPENAI_API_BASE=https://api.mistral.ai/v1
      # - EMBEDDING_PROVIDER=openai
      # - EMBEDDING_MODEL_NAME=mistral-embed
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - anythingllm-network

  # Optional: Add Ollama for local models
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama-data:/root/.ollama
  #   restart: unless-stopped
  #   networks:
  #     - anythingllm-network

  # Optional: Add Qdrant for vector storage
  # qdrant:
  #   image: qdrant/qdrant:latest
  #   container_name: qdrant
  #   ports:
  #     - "6333:6333"
  #   volumes:
  #     - qdrant-data:/qdrant/storage
  #   restart: unless-stopped
  #   networks:
  #     - anythingllm-network

networks:
  anythingllm-network:
    driver: bridge

volumes:
  # ollama-data:
  # qdrant-data:
  anythingllm-storage:
    driver: local
